{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Define file paths\n",
    "pdf_path = \"r3064_buildatable.pdf\"\n",
    "txt_path = \"r3064_buildatable.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF\n",
    "pdf_reader = PdfReader(pdf_path)\n",
    "text_content = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
    "\n",
    "# Save extracted text to a .txt file\n",
    "with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "    txt_file.write(text_content)\n",
    "\n",
    "# Return the path of the extracted text file\n",
    "txt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Chunk Number                                         Text Chunk\n",
      "0             1  How to  \\nBuild a Table\\nAll the Basics Plus  ...\n",
      "1             2  30\"48\"\\n36\"60\"A good furniture maker is part a...\n",
      "2             3  to furniture that is ugly, impractical or both...\n",
      "3             4  this simplicity calls for a thorough knowledge...\n",
      "4             5           Regardless of style, there are many mis-\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load extracted text\n",
    "with open(txt_path, \"r\", encoding=\"utf-8\") as txt_file:\n",
    "    document_text = txt_file.read()\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # Maximum number of characters per chunk\n",
    "    chunk_overlap=30  # Overlap to maintain context between chunks\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "text_chunks = text_splitter.split_text(document_text)\n",
    "\n",
    "# Display a sample of the chunks\n",
    "import pandas as pd\n",
    "df_chunks = pd.DataFrame({\"Chunk Number\": range(1, len(text_chunks) + 1), \"Text Chunk\": text_chunks})\n",
    "print(df_chunks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  # Saves data persistently\n",
    "\n",
    "# Create a collection\n",
    "collection = chroma_client.get_or_create_collection(name=\"table_building_knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avya/Desktop/chatbot/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully stored 298 chunks in ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings for each text chunk\n",
    "embeddings = embedding_model.encode(text_chunks).tolist()  # Convert to list for ChromaDB\n",
    "\n",
    "# Add chunks to ChromaDB\n",
    "for i, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):\n",
    "    collection.add(\n",
    "        ids=[str(i)],  # Unique ID for each chunk\n",
    "        embeddings=[embedding],  # Corresponding vector embedding\n",
    "        metadatas=[{\"text\": chunk}]  # Store text as metadata\n",
    "    )\n",
    "\n",
    "print(f\"✅ Successfully stored {len(text_chunks)} chunks in ChromaDB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to  \n",
      "Build a Table\n",
      "All the Basics Plus  \n",
      "One Beautiful Project Plan\n",
      "and aiming to build a showpiece for your dining room, there are many aspects  of table design that you need to consider.\n",
      "the table to be strong and attractive, and you don’t want wood movement of the top causing problems.\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_docs(query, top_k=10):\n",
    "    \"\"\"Retrieves the top K most relevant text chunks from ChromaDB.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query]).tolist()  # Encode query\n",
    "    results = collection.query(query_embeddings=query_embedding, n_results=top_k)\n",
    "    \n",
    "    retrieved_texts = [match[\"text\"] for match in results[\"metadatas\"][0]]\n",
    "    return retrieved_texts\n",
    "\n",
    "# Example Query\n",
    "query = \"What are the best materials for building a table?\"\n",
    "retrieved_docs = retrieve_relevant_docs(query)\n",
    "print(\"\\n\".join(retrieved_docs))  # Display retrieved knowledge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
